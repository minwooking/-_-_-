{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2117958315770544752\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = glob('C:\\\\workspace\\\\eatand_medicinal_plant\\\\학습용데이터\\\\01.원천데이터\\\\이미지학습용데이터\\\\*')\n",
    "test_dir = glob('C:\\\\workspace\\\\eatand_medicinal_plant\\\\학습용데이터\\\\01.원천데이터\\\\이미지학습용데이터\\\\*')[0]\n",
    "validation_dir = glob('C:\\\\workspace\\\\eatand_medicinal_plant\\\\학습용데이터\\\\01.원천데이터\\\\이미지학습용데이터\\\\*')[2]\n",
    "train_dir = glob('C:\\\\workspace\\\\eatand_medicinal_plant\\\\학습용데이터\\\\01.원천데이터\\\\이미지학습용데이터\\\\*')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\workspace\\\\eatand_medicinal_plant\\\\학습용데이터\\\\01.원천데이터\\\\이미지학습용데이터\\\\train'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6070 images belonging to 15 classes.\n",
      "Found 2037 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # 전처리\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, #  딕셔너리 \n",
    "    target_size= (200,200), # 타겟 사이즈\n",
    "    # 한 번에 전처리할 이미지의 수\n",
    "    batch_size=20,\n",
    "    # 라벨링 : binary 이진라벨링, categorical 다중라벨링 \n",
    "    # 라벨링 방법 : 폴더명의 첫 문자의 알파벳으로 0부터 부여\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size= (200,200),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'구실잣밤나무': 0, '까마귀쪽나무': 1, '꽝꽝나무': 2, '돈나무': 3, '메밀': 4, '백량금': 5, '순비기나무': 6, '좁은잎천선과': 7, '참가시나무': 8, '참꽃나무': 9, '참식나무': 10, '큰조롱': 11, '한라꽃향유': 12, '해국': 13, '황근': 14}\n",
      "{'구실잣밤나무': 0, '까마귀쪽나무': 1, '꽝꽝나무': 2, '돈나무': 3, '메밀': 4, '백량금': 5, '순비기나무': 6, '좁은잎천선과': 7, '참가시나무': 8, '참꽃나무': 9, '참식나무': 10, '큰조롱': 11, '한라꽃향유': 12, '해국': 13, '황근': 14}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices) \n",
    "print(test_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6070 images belonging to 15 classes.\n",
      "Found 2037 images belonging to 15 classes.\n",
      "Found 2018 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "train_dir,\n",
    "target_size=(150,150),\n",
    "class_mode='categorical',\n",
    "batch_size=150\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size= (150,150),\n",
    "    batch_size=150,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "validation_dir,\n",
    "target_size=(150,150),\n",
    "class_mode='categorical',\n",
    "batch_size=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 74, 74, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 72, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 15)                7695      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,479,631\n",
      "Trainable params: 3,479,631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 286s 7s/step - loss: 2.5689 - accuracy: 0.1885 - val_loss: 1.2822 - val_accuracy: 0.5356\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 274s 7s/step - loss: 1.4803 - accuracy: 0.4993 - val_loss: 0.7122 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 270s 7s/step - loss: 1.1132 - accuracy: 0.6801 - val_loss: 1.2359 - val_accuracy: 0.6089\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 270s 7s/step - loss: 0.7042 - accuracy: 0.7672 - val_loss: 0.3965 - val_accuracy: 0.8689\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 269s 7s/step - loss: 0.6786 - accuracy: 0.8101 - val_loss: 0.1441 - val_accuracy: 0.9533\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 270s 7s/step - loss: 0.5492 - accuracy: 0.8402 - val_loss: 0.1529 - val_accuracy: 0.9556\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 270s 7s/step - loss: 0.5196 - accuracy: 0.8672 - val_loss: 0.2419 - val_accuracy: 0.9133\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 270s 7s/step - loss: 0.3032 - accuracy: 0.9041 - val_loss: 0.4417 - val_accuracy: 0.8378\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 271s 7s/step - loss: 0.3130 - accuracy: 0.9039 - val_loss: 0.0842 - val_accuracy: 0.9644\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 271s 7s/step - loss: 0.3865 - accuracy: 0.9030 - val_loss: 0.0691 - val_accuracy: 0.9689\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 291s 7s/step - loss: 0.2926 - accuracy: 0.9137 - val_loss: 0.0482 - val_accuracy: 0.9844\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 323s 8s/step - loss: 0.2479 - accuracy: 0.9280 - val_loss: 0.0315 - val_accuracy: 0.9889\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 309s 8s/step - loss: 0.2068 - accuracy: 0.9361 - val_loss: 0.0616 - val_accuracy: 0.9844\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 302s 8s/step - loss: 0.2548 - accuracy: 0.9274 - val_loss: 0.6405 - val_accuracy: 0.7889\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 302s 8s/step - loss: 0.2153 - accuracy: 0.9309 - val_loss: 0.0808 - val_accuracy: 0.9800\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 304s 8s/step - loss: 0.1526 - accuracy: 0.9605 - val_loss: 0.0711 - val_accuracy: 0.9756\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 303s 8s/step - loss: 0.1326 - accuracy: 0.9578 - val_loss: 0.1340 - val_accuracy: 0.9711\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 302s 8s/step - loss: 0.1844 - accuracy: 0.9551 - val_loss: 0.3237 - val_accuracy: 0.8689\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 301s 8s/step - loss: 0.2181 - accuracy: 0.9410 - val_loss: 0.0278 - val_accuracy: 0.9911\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 304s 8s/step - loss: 0.1251 - accuracy: 0.9637 - val_loss: 0.0148 - val_accuracy: 0.9933\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 302s 8s/step - loss: 0.1679 - accuracy: 0.9632 - val_loss: 0.0402 - val_accuracy: 0.9822\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 302s 8s/step - loss: 0.1861 - accuracy: 0.9539 - val_loss: 0.0195 - val_accuracy: 0.9933\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 302s 8s/step - loss: 0.1038 - accuracy: 0.9706 - val_loss: 0.1753 - val_accuracy: 0.9378\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 298s 7s/step - loss: 0.1555 - accuracy: 0.9628 - val_loss: 0.0127 - val_accuracy: 0.9956\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 292s 7s/step - loss: 0.0612 - accuracy: 0.9807 - val_loss: 0.0154 - val_accuracy: 0.9956\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 294s 7s/step - loss: 0.1041 - accuracy: 0.9708 - val_loss: 0.0666 - val_accuracy: 0.9889\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 299s 7s/step - loss: 0.0842 - accuracy: 0.9733 - val_loss: 0.2985 - val_accuracy: 0.9533\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 293s 7s/step - loss: 0.1770 - accuracy: 0.9601 - val_loss: 0.0167 - val_accuracy: 0.9956\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 292s 7s/step - loss: 0.1212 - accuracy: 0.9676 - val_loss: 0.0561 - val_accuracy: 0.9867\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 295s 7s/step - loss: 0.0751 - accuracy: 0.9772 - val_loss: 0.0594 - val_accuracy: 0.9889\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 289s 7s/step - loss: 0.0951 - accuracy: 0.9713 - val_loss: 0.2386 - val_accuracy: 0.9467\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 296s 7s/step - loss: 0.0783 - accuracy: 0.9784 - val_loss: 0.0106 - val_accuracy: 0.9978\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 307s 8s/step - loss: 0.1515 - accuracy: 0.9632 - val_loss: 0.0664 - val_accuracy: 0.9778\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 304s 8s/step - loss: 0.1075 - accuracy: 0.9713 - val_loss: 0.0271 - val_accuracy: 0.9911\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 296s 7s/step - loss: 0.0560 - accuracy: 0.9846 - val_loss: 0.0650 - val_accuracy: 0.9844\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 291s 7s/step - loss: 0.0824 - accuracy: 0.9769 - val_loss: 0.0293 - val_accuracy: 0.9978\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 307s 8s/step - loss: 0.0780 - accuracy: 0.9797 - val_loss: 0.2495 - val_accuracy: 0.9556\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 303s 8s/step - loss: 0.1104 - accuracy: 0.9684 - val_loss: 0.0169 - val_accuracy: 0.9933\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 301s 8s/step - loss: 0.0692 - accuracy: 0.9814 - val_loss: 0.0462 - val_accuracy: 0.9889\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 305s 8s/step - loss: 0.2482 - accuracy: 0.9655 - val_loss: 0.0097 - val_accuracy: 0.9978\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 306s 8s/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.1035 - val_accuracy: 0.9756\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 306s 8s/step - loss: 0.1301 - accuracy: 0.9721 - val_loss: 0.0102 - val_accuracy: 0.9978\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 304s 8s/step - loss: 0.0900 - accuracy: 0.9770 - val_loss: 0.0662 - val_accuracy: 0.9889\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 308s 8s/step - loss: 0.1093 - accuracy: 0.9736 - val_loss: 0.0145 - val_accuracy: 0.9956\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 306s 8s/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.0124 - val_accuracy: 0.9956\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 306s 8s/step - loss: 0.0590 - accuracy: 0.9836 - val_loss: 0.2583 - val_accuracy: 0.9467\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 300s 7s/step - loss: 0.0905 - accuracy: 0.9785 - val_loss: 0.0080 - val_accuracy: 0.9978\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 294s 7s/step - loss: 0.0887 - accuracy: 0.9824 - val_loss: 0.0341 - val_accuracy: 0.9911\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 301s 7s/step - loss: 0.0589 - accuracy: 0.9855 - val_loss: 0.0212 - val_accuracy: 0.9933\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 305s 8s/step - loss: 0.0621 - accuracy: 0.9846 - val_loss: 0.0119 - val_accuracy: 0.9933\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 305s 8s/step - loss: 0.0774 - accuracy: 0.9802 - val_loss: 0.0303 - val_accuracy: 0.9956\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 310s 8s/step - loss: 0.1562 - accuracy: 0.9752 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 320s 8s/step - loss: 0.1256 - accuracy: 0.9777 - val_loss: 0.4629 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 321s 8s/step - loss: 0.0660 - accuracy: 0.9834 - val_loss: 0.0196 - val_accuracy: 0.9933\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 327s 8s/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.0165 - val_accuracy: 0.9956\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 321s 8s/step - loss: 0.0703 - accuracy: 0.9853 - val_loss: 0.0397 - val_accuracy: 0.9911\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 314s 8s/step - loss: 0.1161 - accuracy: 0.9740 - val_loss: 0.0488 - val_accuracy: 0.9889\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 299s 7s/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 0.0843 - val_accuracy: 0.9889\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 297s 7s/step - loss: 0.0462 - accuracy: 0.9867 - val_loss: 0.0309 - val_accuracy: 0.9956\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 295s 7s/step - loss: 0.0454 - accuracy: 0.9892 - val_loss: 0.0782 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 291s 7s/step - loss: 0.0666 - accuracy: 0.9816 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 292s 7s/step - loss: 0.0424 - accuracy: 0.9880 - val_loss: 0.1161 - val_accuracy: 0.9778\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 293s 7s/step - loss: 0.1444 - accuracy: 0.9767 - val_loss: 0.0454 - val_accuracy: 0.9933\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 294s 7s/step - loss: 0.0589 - accuracy: 0.9875 - val_loss: 0.0415 - val_accuracy: 0.9889\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 298s 7s/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.0235 - val_accuracy: 0.9956\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 332s 8s/step - loss: 0.1251 - accuracy: 0.9792 - val_loss: 0.5218 - val_accuracy: 0.9022\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 291s 7s/step - loss: 0.0646 - accuracy: 0.9846 - val_loss: 0.0520 - val_accuracy: 0.9956\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 293s 7s/step - loss: 0.0867 - accuracy: 0.9807 - val_loss: 0.0506 - val_accuracy: 0.9933\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 296s 7s/step - loss: 0.0968 - accuracy: 0.9791 - val_loss: 0.0147 - val_accuracy: 0.9933\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 294s 7s/step - loss: 0.0651 - accuracy: 0.9843 - val_loss: 0.0084 - val_accuracy: 0.9956\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 299s 7s/step - loss: 0.1584 - accuracy: 0.9765 - val_loss: 0.0181 - val_accuracy: 0.9956\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 302s 8s/step - loss: 0.0572 - accuracy: 0.9875 - val_loss: 0.0227 - val_accuracy: 0.9956\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 298s 7s/step - loss: 0.0614 - accuracy: 0.9846 - val_loss: 0.0918 - val_accuracy: 0.9867\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 298s 7s/step - loss: 0.0852 - accuracy: 0.9823 - val_loss: 0.0176 - val_accuracy: 0.9956\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9858"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "  # This is the first convolution\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  # The second convolution\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  # The third convolution\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  # The fourth convolution\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  # Flatten the results to feed into a DNN\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  # 512 neuron hidden layer\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(15, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=100, steps_per_epoch=40, validation_data = validation_generator, verbose = 1, validation_steps=3)\n",
    "\n",
    "# model.save(\"image1.h5\")\n",
    "\n",
    "# history = model.fit(train_generator, epochs=50, steps_per_epoch=40, validation_data = validation_generator, verbose = 1, validation_steps=3)\n",
    "# model.save(\"image2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loadmodel = load_model('image1.h5')\n",
    "\n",
    "# 3. 모델 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(loadmodel)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
